{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pybrain\n",
    "import numpy as np\n",
    "from pybrain.structure import FeedForwardNetwork\n",
    "from pybrain.structure import LinearLayer, SigmoidLayer\n",
    "from pybrain.structure import FullConnection\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import random\n",
    "import ast\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import glob\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import pprint\n",
    "import re\n",
    "from sklearn import linear_model, datasets\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn import svm\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import gevent.monkey\n",
    "gevent.monkey.patch_socket()\n",
    "import numpy\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "from sqlalchemy.dialects.mysql import LONGTEXT\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import gevent\n",
    "import datetime\n",
    "import marshal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "mysql_url = \"mysql://forex:yummy4money@forex.c2ggnaqt6wye.us-west-1.rds.amazonaws.com/forex\"\n",
    "sqlite_url = 'sqlite:///database.db'\n",
    "db = create_engine(mysql_url, echo=False)\n",
    "session = sessionmaker()\n",
    "session.configure(bind=db)\n",
    "session = session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"select a.timestamp, ((a.open + a.close) / 2), ((b.open + b.close) / 2)  from \n",
    "\n",
    "            forex_data a\n",
    "            join \n",
    "            forex_data b\n",
    "            where a.timestamp = b.timestamp\n",
    "            and a.exchange = 'EURUSD' \n",
    "            and b.exchange = 'EURGBP'\n",
    "            \n",
    "            order by a.timestamp asc limit %s\"\"\"\n",
    "\n",
    "query = \"\"\"SELECT  timestamp,\n",
    "        MAX(CASE WHEN exchange = 'EURUSD' THEN ((open + close) / 2) END) USDEUR,\n",
    "        MAX(CASE WHEN exchange = 'EURGBP' THEN ((open + close) / 2) END) GBPEUR,\n",
    "        MAX(CASE WHEN exchange = 'USDJPY' THEN ((open + close) / 2) END) USDJPY\n",
    "FROM    forex_data\n",
    "GROUP   BY timestamp\n",
    "ORDER   BY timestamp\n",
    "LIMIT %s\"\"\"\n",
    "row_count = 2000000\n",
    "query_formatted = query % row_count\n",
    "result = db.engine.execute(query_formatted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_data = []\n",
    "past_value = \"\"\n",
    "for row in result:\n",
    "    if str(row.values()[0].date()) == past_value:\n",
    "        grouped_data[len(grouped_data)-1].append([float(row.values()[1:])\n",
    "    else:\n",
    "        grouped_data.append([[float(row.values()[1]), float(row.values()[2])]])\n",
    "        past_value = str(row.values()[0].date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pylearn2.datasets.dense_design_matrix import DenseDesignMatrix\n",
    "\n",
    "data = grouped_data\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "offset = 5\n",
    "infill = 7\n",
    "num_samples = 400\n",
    "\n",
    "for i in xrange(len(data)):\n",
    "    if len(data[i]) > 1000:\n",
    "        for j in xrange(len(data[i])):\n",
    "            if j > num_samples and j < len(data[i]) - offset and j % infill == 0:\n",
    "                row = np.ravel(data[i][j-num_samples:j], order='F')\n",
    "                eurusd = row[:num_samples]\n",
    "                eurgbp = row[num_samples:]\n",
    "                average_eurusd = sum(eurusd) / float(len(eurusd))\n",
    "                average_eurgbp = sum(eurgbp) / float(len(eurgbp))\n",
    "                \n",
    "                out = [(item - average_eurusd) / average_eurusd * 100. for item in eurusd]\n",
    "                out.extend([(item - average_eurgbp) / average_eurgbp * 100. for item in eurgbp])\n",
    "                x.append(out)\n",
    "                y.append([1, 0] if data[i][j+offset][0] > data[i][j][0] else [0, 1])\n",
    "\n",
    "X = numpy.asarray(x)\n",
    "Y = numpy.asarray(y)\n",
    "    \n",
    "def load_data(start, stop):\n",
    "    \n",
    "    X_out = X[start:stop, :]\n",
    "    Y_out = Y[start:stop, :]\n",
    " \n",
    "    return DenseDesignMatrix(X=X_out, y=Y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " ..., \n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "113876\n",
      "113876\n",
      "(113876, 800)\n",
      "(113876, 2)\n"
     ]
    }
   ],
   "source": [
    "test = load_data(0, 50000)\n",
    "print test.y\n",
    "print len(X)\n",
    "print len(Y)\n",
    "print np.shape(X)\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25642\n",
      "24359\n",
      "0.487170256595\n"
     ]
    }
   ],
   "source": [
    "zero = 0\n",
    "one = 1\n",
    "for item in test.y:\n",
    "    if item[0] == 0:\n",
    "        zero += 1\n",
    "    else:\n",
    "        one += 1\n",
    "print zero\n",
    "print one\n",
    "\n",
    "print float(one) / (zero + one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "\n",
    "import pylearn2\n",
    "import numpy as np\n",
    "from pylearn2.train import Train\n",
    "from pylearn2.datasets.mnist import MNIST\n",
    "from pylearn2.models import softmax_regression, mlp, svm\n",
    "from pylearn2.training_algorithms import bgd, sgd\n",
    "from pylearn2.termination_criteria import MonitorBased, EpochCounter\n",
    "from pylearn2.train_extensions import best_params, live_monitoring\n",
    "from pylearn2.utils import serial\n",
    "from pylearn2.costs.mlp.dropout import Dropout\n",
    "from pylearn2.costs.mlp import WeightDecay\n",
    "from theano import function\n",
    "from theano import tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = 90000\n",
    "test_percent = .12\n",
    "train = load_data(0, num_samples)\n",
    "valid = load_data(num_samples, num_samples + num_samples * test_percent)\n",
    "train_monitor = load_data(0, num_samples * test_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monitor = live_monitoring.LiveMonitoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.monitor.disable_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100800.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples + num_samples * test_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter and initial learning rate summary:\n",
      "\th0_W: 9.99999971718e-10\n",
      "\th0_b: 9.99999971718e-10\n",
      "\th1_W: 9.99999971718e-10\n",
      "\th1_b: 9.99999971718e-10\n",
      "\tsoftmax_b: 9.99999971718e-10\n",
      "\tsoftmax_W: 9.99999971718e-10\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 1.006992 seconds\n",
      "Time this epoch: 2.554327 seconds\n",
      "Time this epoch: 2.556621 seconds\n",
      "Time this epoch: 2.578473 seconds\n",
      "Time this epoch: 2.571318 seconds\n",
      "Time this epoch: 2.514875 seconds\n",
      "Time this epoch: 2.483712 seconds\n",
      "Time this epoch: 2.495808 seconds\n",
      "Time this epoch: 2.516994 seconds\n",
      "Time this epoch: 2.433262 seconds\n",
      "Time this epoch: 2.417404 seconds\n",
      "Time this epoch: 2.424127 seconds\n",
      "Time this epoch: 2.496858 seconds\n",
      "Time this epoch: 2.501022 seconds\n",
      "Time this epoch: 2.433513 seconds\n",
      "Time this epoch: 2.430407 seconds\n",
      "Time this epoch: 2.438729 seconds\n",
      "Time this epoch: 2.488536 seconds\n",
      "Time this epoch: 2.460550 seconds\n",
      "Time this epoch: 2.449741 seconds\n",
      "Time this epoch: 2.447867 seconds\n",
      "Time this epoch: 2.427213 seconds\n",
      "Time this epoch: 2.439789 seconds\n",
      "Time this epoch: 2.424643 seconds\n",
      "Time this epoch: 2.446074 seconds\n",
      "Time this epoch: 2.415841 seconds\n",
      "Time this epoch: 2.447452 seconds\n",
      "Time this epoch: 2.488767 seconds\n",
      "Time this epoch: 2.493280 seconds\n",
      "Time this epoch: 2.515529 seconds\n",
      "Time this epoch: 2.463964 seconds\n",
      "Time this epoch: 2.437385 seconds\n",
      "Time this epoch: 2.448268 seconds\n",
      "Time this epoch: 2.411605 seconds\n",
      "Time this epoch: 2.447774 seconds\n",
      "Time this epoch: 2.500234 seconds\n",
      "Time this epoch: 2.499952 seconds\n",
      "Time this epoch: 2.497221 seconds\n",
      "Time this epoch: 2.449149 seconds\n",
      "Time this epoch: 2.453259 seconds\n",
      "Time this epoch: 2.513449 seconds\n",
      "Time this epoch: 2.516541 seconds\n",
      "Time this epoch: 2.469605 seconds\n",
      "Time this epoch: 2.427249 seconds\n",
      "Time this epoch: 2.435727 seconds\n",
      "Time this epoch: 2.440375 seconds\n",
      "Time this epoch: 2.428725 seconds\n",
      "Time this epoch: 2.443766 seconds\n",
      "Time this epoch: 2.433926 seconds\n",
      "Time this epoch: 2.431943 seconds\n",
      "Time this epoch: 2.428116 seconds\n",
      "Time this epoch: 2.413453 seconds\n",
      "Time this epoch: 2.465003 seconds\n",
      "Time this epoch: 2.439236 seconds\n",
      "Time this epoch: 2.434128 seconds\n",
      "Time this epoch: 2.439499 seconds\n",
      "Time this epoch: 2.510575 seconds\n",
      "Time this epoch: 2.500388 seconds\n",
      "Time this epoch: 2.425817 seconds\n",
      "Time this epoch: 2.435139 seconds\n",
      "Time this epoch: 2.459104 seconds\n",
      "Time this epoch: 2.463363 seconds\n",
      "Time this epoch: 2.444141 seconds\n",
      "Time this epoch: 2.478729 seconds\n",
      "Time this epoch: 2.476401 seconds\n",
      "Time this epoch: 2.484723 seconds\n",
      "Time this epoch: 2.455914 seconds\n",
      "Time this epoch: 2.431360 seconds\n",
      "Time this epoch: 2.437620 seconds\n",
      "Time this epoch: 2.415879 seconds\n",
      "Time this epoch: 2.414082 seconds\n",
      "Time this epoch: 2.430272 seconds\n",
      "Time this epoch: 2.493101 seconds\n",
      "Time this epoch: 2.450132 seconds\n",
      "Time this epoch: 2.487855 seconds\n",
      "Time this epoch: 2.489180 seconds\n",
      "Time this epoch: 2.470815 seconds\n",
      "Time this epoch: 2.467739 seconds\n",
      "Time this epoch: 2.513730 seconds\n",
      "Time this epoch: 2.504079 seconds\n",
      "Time this epoch: 2.484118 seconds\n",
      "Time this epoch: 2.418856 seconds\n",
      "Time this epoch: 2.438993 seconds\n",
      "Time this epoch: 2.492565 seconds\n",
      "Time this epoch: 2.467162 seconds\n",
      "Time this epoch: 2.448816 seconds\n",
      "Time this epoch: 2.494807 seconds\n",
      "Time this epoch: 2.482458 seconds\n",
      "Time this epoch: 2.509162 seconds\n",
      "Time this epoch: 2.503262 seconds\n",
      "Time this epoch: 2.495418 seconds\n",
      "Time this epoch: 2.504097 seconds\n",
      "Time this epoch: 2.511868 seconds\n",
      "Time this epoch: 2.478969 seconds\n",
      "Time this epoch: 2.481563 seconds\n",
      "Time this epoch: 2.883165 seconds\n",
      "Time this epoch: 2.469197 seconds\n",
      "Time this epoch: 2.468813 seconds\n",
      "Time this epoch: 2.445691 seconds\n",
      "Time this epoch: 2.453609 seconds\n",
      "Time this epoch: 2.431896 seconds\n",
      "Time this epoch: 2.433905 seconds\n",
      "Time this epoch: 2.441277 seconds\n",
      "Time this epoch: 2.474400 seconds\n",
      "Time this epoch: 2.441796 seconds\n",
      "Time this epoch: 2.427141 seconds\n",
      "Time this epoch: 2.430281 seconds\n",
      "Time this epoch: 2.422576 seconds\n",
      "Time this epoch: 2.456262 seconds\n",
      "Time this epoch: 2.489173 seconds\n",
      "Time this epoch: 2.491601 seconds\n",
      "Time this epoch: 2.522738 seconds\n",
      "Time this epoch: 2.429688 seconds\n",
      "Time this epoch: 2.463164 seconds\n",
      "Time this epoch: 2.493599 seconds\n",
      "Time this epoch: 2.480058 seconds\n",
      "Time this epoch: 2.432756 seconds\n",
      "Time this epoch: 2.451622 seconds\n",
      "Time this epoch: 2.493616 seconds\n",
      "Time this epoch: 2.502031 seconds\n",
      "Time this epoch: 2.468880 seconds\n",
      "Time this epoch: 2.487682 seconds\n",
      "Time this epoch: 2.486389 seconds\n",
      "Time this epoch: 2.482778 seconds\n",
      "Time this epoch: 2.429060 seconds\n",
      "Time this epoch: 2.459926 seconds\n",
      "Time this epoch: 2.475470 seconds\n",
      "Time this epoch: 2.438675 seconds\n",
      "Time this epoch: 2.419130 seconds\n",
      "Time this epoch: 2.425354 seconds\n",
      "Time this epoch: 2.422459 seconds\n",
      "Time this epoch: 2.427627 seconds\n",
      "Time this epoch: 2.460575 seconds\n",
      "Time this epoch: 2.491819 seconds\n",
      "Time this epoch: 2.483088 seconds\n",
      "Time this epoch: 2.418031 seconds\n",
      "Time this epoch: 2.434088 seconds\n",
      "Time this epoch: 2.479146 seconds\n",
      "Time this epoch: 2.509627 seconds\n",
      "Time this epoch: 2.489080 seconds\n",
      "Time this epoch: 2.515891 seconds\n",
      "Time this epoch: 2.451166 seconds\n",
      "Time this epoch: 2.456657 seconds\n",
      "Time this epoch: 2.447768 seconds\n",
      "Time this epoch: 2.428992 seconds\n",
      "Time this epoch: 2.434214 seconds\n",
      "Time this epoch: 2.467607 seconds\n",
      "Time this epoch: 2.431282 seconds\n",
      "Time this epoch: 2.432109 seconds\n",
      "Time this epoch: 2.419465 seconds\n",
      "Time this epoch: 2.464131 seconds\n",
      "Time this epoch: 2.538363 seconds\n",
      "Time this epoch: 2.811043 seconds\n",
      "Time this epoch: 2.803939 seconds\n",
      "Time this epoch: 2.804012 seconds\n",
      "Time this epoch: 2.513505 seconds\n",
      "Time this epoch: 2.497617 seconds\n",
      "Time this epoch: 2.494477 seconds\n",
      "Time this epoch: 2.494585 seconds\n",
      "Time this epoch: 2.485756 seconds\n",
      "Time this epoch: 2.503440 seconds\n",
      "Time this epoch: 2.530854 seconds\n",
      "Time this epoch: 2.664924 seconds\n",
      "Time this epoch: 2.434788 seconds\n",
      "Time this epoch: 2.445035 seconds\n",
      "Time this epoch: 2.492100 seconds\n",
      "Time this epoch: 2.480923 seconds\n",
      "Time this epoch: 2.406222 seconds\n",
      "Time this epoch: 2.413845 seconds\n",
      "Time this epoch: 2.470477 seconds\n",
      "Time this epoch: 2.421268 seconds\n",
      "Time this epoch: 2.438261 seconds\n",
      "Time this epoch: 2.430475 seconds\n",
      "Time this epoch: 2.442266 seconds\n",
      "Time this epoch: 2.421859 seconds\n",
      "Time this epoch: 2.427822 seconds\n",
      "Time this epoch: 2.482665 seconds\n",
      "Time this epoch: 2.514576 seconds\n",
      "Time this epoch: 2.488341 seconds\n",
      "Time this epoch: 2.492211 seconds\n",
      "Time this epoch: 2.495220 seconds\n",
      "Time this epoch: 2.489903 seconds\n",
      "Time this epoch: 2.508072 seconds\n",
      "Time this epoch: 2.453732 seconds\n",
      "Time this epoch: 2.441613 seconds\n",
      "Time this epoch: 2.453495 seconds\n",
      "Time this epoch: 2.425980 seconds\n",
      "Time this epoch: 2.430875 seconds\n",
      "Time this epoch: 2.430503 seconds\n",
      "Time this epoch: 2.428940 seconds\n",
      "Time this epoch: 2.420937 seconds\n",
      "Time this epoch: 2.423193 seconds\n",
      "Time this epoch: 2.436523 seconds\n",
      "Time this epoch: 2.439180 seconds\n",
      "Time this epoch: 2.460564 seconds\n",
      "Time this epoch: 2.484739 seconds\n",
      "Time this epoch: 2.510705 seconds\n",
      "Time this epoch: 2.421657 seconds\n",
      "Time this epoch: 2.445282 seconds\n",
      "Time this epoch: 2.442525 seconds\n",
      "Time this epoch: 2.427667 seconds\n",
      "Time this epoch: 2.424903 seconds\n",
      "Time this epoch: 2.462741 seconds\n",
      "Time this epoch: 2.437097 seconds\n",
      "Time this epoch: 2.427067 seconds\n",
      "Time this epoch: 2.454227 seconds\n",
      "Time this epoch: 2.448017 seconds\n",
      "Time this epoch: 2.431866 seconds\n",
      "Time this epoch: 2.445860 seconds\n",
      "Time this epoch: 2.433453 seconds\n",
      "Time this epoch: 2.425192 seconds\n",
      "Time this epoch: 2.418905 seconds\n",
      "Time this epoch: 2.437165 seconds\n",
      "Time this epoch: 2.478314 seconds\n",
      "Time this epoch: 2.495777 seconds\n",
      "Time this epoch: 2.486869 seconds\n",
      "Time this epoch: 2.426559 seconds\n",
      "Time this epoch: 2.444672 seconds\n",
      "Time this epoch: 2.422531 seconds\n",
      "Time this epoch: 2.442051 seconds\n",
      "Time this epoch: 2.487461 seconds\n",
      "Time this epoch: 2.500992 seconds\n",
      "Time this epoch: 2.663552 seconds\n",
      "Time this epoch: 2.491912 seconds\n",
      "Time this epoch: 2.476359 seconds\n",
      "Time this epoch: 2.431995 seconds\n",
      "Time this epoch: 2.439051 seconds\n",
      "Time this epoch: 2.424913 seconds\n",
      "Time this epoch: 2.428173 seconds\n",
      "Time this epoch: 2.439150 seconds\n",
      "Time this epoch: 2.460380 seconds\n",
      "Time this epoch: 2.424904 seconds\n",
      "Time this epoch: 2.427595 seconds\n",
      "Time this epoch: 2.405491 seconds\n",
      "Time this epoch: 2.413135 seconds\n",
      "Time this epoch: 2.465869 seconds\n",
      "Time this epoch: 2.500764 seconds\n",
      "Time this epoch: 2.489388 seconds\n",
      "Time this epoch: 2.782632 seconds\n",
      "Time this epoch: 2.420704 seconds\n",
      "Time this epoch: 2.488434 seconds\n",
      "Time this epoch: 2.417615 seconds\n",
      "Time this epoch: 2.429243 seconds\n",
      "Time this epoch: 2.426439 seconds\n",
      "Time this epoch: 2.439261 seconds\n",
      "Time this epoch: 2.439048 seconds\n",
      "Time this epoch: 2.456525 seconds\n",
      "Time this epoch: 2.459362 seconds\n",
      "Time this epoch: 2.501390 seconds\n",
      "Time this epoch: 2.482217 seconds\n",
      "Time this epoch: 2.491982 seconds\n",
      "Time this epoch: 2.454183 seconds\n",
      "Time this epoch: 2.438613 seconds\n",
      "Time this epoch: 2.463129 seconds\n",
      "Time this epoch: 2.645589 seconds\n",
      "Time this epoch: 2.745495 seconds\n",
      "Time this epoch: 2.691879 seconds\n",
      "Time this epoch: 2.505041 seconds\n",
      "Time this epoch: 2.445574 seconds\n",
      "Time this epoch: 2.414150 seconds\n",
      "Time this epoch: 2.427586 seconds\n",
      "Time this epoch: 2.441286 seconds\n",
      "Time this epoch: 2.428900 seconds\n",
      "Time this epoch: 2.474044 seconds\n",
      "Time this epoch: 2.476273 seconds\n",
      "Time this epoch: 2.469261 seconds\n",
      "Time this epoch: 2.485317 seconds\n",
      "Time this epoch: 2.471676 seconds\n",
      "Time this epoch: 2.418881 seconds\n",
      "Time this epoch: 2.467647 seconds\n",
      "Time this epoch: 2.495278 seconds\n",
      "Time this epoch: 2.480761 seconds\n",
      "Time this epoch: 2.457094 seconds\n",
      "Time this epoch: 2.406945 seconds\n",
      "Time this epoch: 2.431927 seconds\n",
      "Time this epoch: 2.439778 seconds\n",
      "Time this epoch: 2.463705 seconds\n",
      "Time this epoch: 2.490196 seconds\n",
      "Time this epoch: 2.440292 seconds\n",
      "Time this epoch: 2.490836 seconds\n",
      "Time this epoch: 2.498942 seconds\n",
      "Time this epoch: 2.686718 seconds\n",
      "Time this epoch: 2.426543 seconds\n",
      "Time this epoch: 2.430699 seconds\n",
      "Time this epoch: 2.421090 seconds\n",
      "Time this epoch: 2.465417 seconds\n",
      "Time this epoch: 2.464029 seconds\n",
      "Time this epoch: 2.442882 seconds\n",
      "Time this epoch: 2.463633 seconds\n",
      "Time this epoch: 2.438545 seconds\n",
      "Time this epoch: 2.429754 seconds\n",
      "Time this epoch: 2.407719 seconds\n",
      "Time this epoch: 2.415338 seconds\n",
      "Time this epoch: 2.402068 seconds\n",
      "Time this epoch: 2.412908 seconds\n",
      "Time this epoch: 2.402557 seconds\n",
      "Time this epoch: 2.408525 seconds\n",
      "Time this epoch: 2.437051 seconds\n",
      "Time this epoch: 2.413107 seconds\n",
      "Time this epoch: 2.418571 seconds\n",
      "Time this epoch: 2.413613 seconds\n",
      "Time this epoch: 2.418075 seconds\n",
      "Time this epoch: 2.430230 seconds\n",
      "Time this epoch: 2.411179 seconds\n",
      "Time this epoch: 2.416242 seconds\n",
      "Time this epoch: 2.417070 seconds\n",
      "Time this epoch: 2.408071 seconds\n",
      "Time this epoch: 2.416891 seconds\n",
      "Time this epoch: 2.419360 seconds\n",
      "Time this epoch: 2.408121 seconds\n",
      "Time this epoch: 2.413685 seconds\n",
      "Time this epoch: 2.408024 seconds\n",
      "Time this epoch: 2.415005 seconds\n",
      "Time this epoch: 2.405929 seconds\n",
      "Time this epoch: 2.431488 seconds\n",
      "Time this epoch: 2.436478 seconds\n",
      "Time this epoch: 2.420206 seconds\n",
      "Time this epoch: 2.414518 seconds\n",
      "Time this epoch: 2.414068 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-ea119c1e75c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtrain_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/temp/pylearn2/pylearn2/train.pyc\u001b[0m in \u001b[0;36mmain_loop\u001b[1;34m(self, time_budget)\u001b[0m\n\u001b[0;32m    213\u001b[0m                                          \"continues.\")\n\u001b[0;32m    214\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                     \u001b[0mextension_continue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_callbacks_and_monitoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_epochs_seen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/temp/pylearn2/pylearn2/train.pyc\u001b[0m in \u001b[0;36mrun_callbacks_and_monitoring\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[0mextension\u001b[0m \u001b[0mwants\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstop\u001b[0m \u001b[0mlearning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \"\"\"\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[0mcontinue_learning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/temp/pylearn2/pylearn2/monitor.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m                     \u001b[1;31m# X is a flat (not nested) tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_prereqs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m                     \u001b[0ma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m                     \u001b[0mactual_ne\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_data_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[1;31m# end for X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/temp/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "monitor.req_sock.close()\n",
    "monitor.pub_sock.close()\n",
    "monitor = live_monitoring.LiveMonitoring()\n",
    "\n",
    "h0 = mlp.RectifiedLinear(layer_name='h0', dim=800, sparse_init=800)\n",
    "h1 = mlp.RectifiedLinear(layer_name='h1', dim=800, sparse_init=800)\n",
    "ylayer = mlp.Softmax(layer_name='y', n_classes=2, irange=0)\n",
    "\n",
    "layers = [h0, h1, ylayer]\n",
    "model = mlp.MLP(layers, nvis=800)\n",
    "\n",
    "monitoring = dict(valid=valid, train=train_monitor)\n",
    "termination = EpochCounter(1000)\n",
    "extensions = [monitor]\n",
    "\n",
    "algorithm = sgd.SGD(.000000001, batch_size=200, cost=Dropout(.8),\n",
    "                     monitoring_dataset = monitoring, termination_criterion = termination)\n",
    "\n",
    "#algorithm = bgd.BGD(batch_size=2000, cost=WeightDecay({'h0':1., 'h1':1.}),\n",
    " #                   monitoring_dataset = monitoring, termination_criterion = termination)\n",
    "\n",
    "train_job = Train(train, model, algorithm, extensions=extensions)\n",
    "\n",
    "\n",
    "train_job.main_loop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#monitoring = dict(valid=valid)\n",
    "monitoring = dict()\n",
    "#termination = MonitorBased(channel_name=\"valid_y_misclass\", N=100)\n",
    "termination = EpochCounter(10)\n",
    "#extensions = [best_params.MonitorBasedSaveBest(channel_name=\"valid_y_misclass\",\n",
    "#save_path=\"train_best.pkl\"), monitor]\n",
    "extensions = [monitor]\n",
    "\n",
    "\n",
    "algorithm = sgd.SGD(0.1, batch_size=100, cost=Dropout(),\n",
    "                    monitoring_dataset = monitoring, termination_criterion = termination)\n",
    "\n",
    "save_path = \"train_bes3t.pkl\"\n",
    "#if os.path.exists(save_path):\n",
    "#    model = serial.load(save_path)\n",
    "#else:\n",
    "#    print 'Running training'\n",
    "#    train_job = Train(train, model, algorithm, extensions=extensions, save_path=\"train.pkl\", save_freq=1)\n",
    "#    train_job.main_loop()\n",
    "\n",
    "train_job = Train(train, model, algorithm, extensions=extensions, save_path=\"train.pkl\", save_freq=1)\n",
    "train_job.main_loop()\n",
    "\n",
    "\n",
    "#X = model.get_input_space().make_batch_theano()\n",
    "#Y = model.fprop(X)\n",
    "\n",
    "#y = T.argmax(Y, axis=1)\n",
    "#f = function([X], y)\n",
    "#yhat = f(test.X)\n",
    "\n",
    "#y = np.where(test.get_targets())[1]\n",
    "#print 'accuracy', (y==yhat).sum() / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pybrain\n",
    "import numpy as np\n",
    "from pybrain.structure import FeedForwardNetwork\n",
    "from pybrain.structure import LinearLayer, SigmoidLayer\n",
    "from pybrain.structure import FullConnection\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import random\n",
    "import ast\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import glob\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import pprint\n",
    "import re\n",
    "from sklearn import linear_model, datasets\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn import svm\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import gevent.monkey\n",
    "gevent.monkey.patch_socket()\n",
    "import numpy\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "from sqlalchemy.dialects.mysql import LONGTEXT\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import gevent\n",
    "import datetime\n",
    "import marshal\n",
    "from pylearn2.datasets.dense_design_matrix import DenseDesignMatrix\n",
    "\n",
    "from __future__ import division\n",
    "import os\n",
    "\n",
    "import pylearn2\n",
    "import numpy as np\n",
    "from pylearn2.train import Train\n",
    "from pylearn2.datasets.mnist import MNIST\n",
    "from pylearn2.models import softmax_regression, mlp, svm\n",
    "from pylearn2.training_algorithms import bgd, sgd\n",
    "from pylearn2.termination_criteria import MonitorBased, EpochCounter\n",
    "from pylearn2.train_extensions import best_params, live_monitoring\n",
    "from pylearn2.utils import serial\n",
    "from pylearn2.costs.mlp.dropout import Dropout\n",
    "from pylearn2.costs.mlp import WeightDecay\n",
    "from theano import function\n",
    "from theano import tensor as T\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainfile = open('usd_eur_trainingdata.csv', 'r')\n",
    "testfile = open('usd_eur_testingdata.csv', 'r')\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for line in trainfile:\n",
    "    line = line.strip().split(',')\n",
    "    features = line[:-3]\n",
    "    outputs = line[-3:]\n",
    "    X_train.append(features)\n",
    "    Y_train.append([outputs[0]])\n",
    "\n",
    "for line in testfile:\n",
    "    line = line.strip().split(',')\n",
    "    features = line[:-3]\n",
    "    outputs = line[-3:]\n",
    "    X_test.append(features)\n",
    "    Y_test.append([outputs[0]])\n",
    "\n",
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "Y_train = np.asarray(Y_train).astype(np.float32)\n",
    "\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "Y_test = np.asarray(Y_test).astype(np.float32)\n",
    "\n",
    "def normalize_up_down(x, y):\n",
    "    samples = zip(x, y)\n",
    "    numpy.random.shuffle(samples)\n",
    "    up = []\n",
    "    down = []\n",
    "    for item in samples:\n",
    "        if item[1][0] > 0:\n",
    "            up.append(item)\n",
    "        elif item[1][0] < 0:\n",
    "            down.append(item)\n",
    "    min_length = min(len(up), len(down))\n",
    "    out = up[:min_length] + down[:min_length]\n",
    "    numpy.random.shuffle(out)\n",
    "    return zip(*out)\n",
    "\n",
    "\n",
    "X_train, Y_train = normalize_up_down(X_train, Y_train)\n",
    "X_test, Y_test = normalize_up_down(X_test, Y_test)\n",
    "\n",
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "Y_train = np.asarray(Y_train).astype(np.float32)\n",
    "\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "Y_test = np.asarray(Y_test).astype(np.float32)\n",
    "\n",
    "Y_train = Y_train * 10000\n",
    "Y_test = Y_test * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3418\n",
      "3418\n",
      "350\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "print len(X_train)\n",
    "print len(Y_train)\n",
    "print len(X_test)\n",
    "print len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3418, 9)\n",
      "(3418, 1)\n",
      "(350, 9)\n",
      "(350, 1)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(X_train)\n",
    "print np.shape(Y_train)\n",
    "\n",
    "print np.shape(X_test)\n",
    "print np.shape(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train = DenseDesignMatrix(X=X_train, y=Y_train)\n",
    "valid = DenseDesignMatrix(X=X_test[::5], y=Y_test[::5])\n",
    "train_monitor = DenseDesignMatrix(X=X_train[::5], y=Y_train[::5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monitor = live_monitoring.LiveMonitoring()\n",
    "firstrun = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter and initial learning rate summary:\n",
      "\th0_W: 0.0010000000475\n",
      "\th0_b: 0.0010000000475\n",
      "\th1_W: 0.0010000000475\n",
      "\th1_b: 0.0010000000475\n",
      "\ty_W: 0.0010000000475\n",
      "\ty_b: 0.0010000000475\n",
      "Compiling sgd_update...\n",
      "Compiling sgd_update done. Time elapsed: 0.439808 seconds\n",
      "Time this epoch: 0.054793 seconds\n",
      "Time this epoch: 0.054871 seconds\n",
      "Time this epoch: 0.054934 seconds\n",
      "Time this epoch: 0.054364 seconds\n",
      "Time this epoch: 0.051033 seconds\n",
      "Time this epoch: 0.050953 seconds\n",
      "Time this epoch: 0.051165 seconds\n",
      "Time this epoch: 0.051197 seconds\n",
      "Time this epoch: 0.051314 seconds\n",
      "Time this epoch: 0.050951 seconds\n",
      "Time this epoch: 0.051048 seconds\n",
      "Time this epoch: 0.051207 seconds\n",
      "Time this epoch: 0.051228 seconds\n",
      "Time this epoch: 0.051119 seconds\n",
      "Time this epoch: 0.051250 seconds\n",
      "Time this epoch: 0.051183 seconds\n",
      "Time this epoch: 0.051846 seconds\n",
      "Time this epoch: 0.050792 seconds\n",
      "Time this epoch: 0.050803 seconds\n",
      "Time this epoch: 0.050571 seconds\n",
      "Time this epoch: 0.050866 seconds\n",
      "Time this epoch: 0.050755 seconds\n",
      "Time this epoch: 0.050709 seconds\n",
      "Time this epoch: 0.050419 seconds\n",
      "Time this epoch: 0.050708 seconds\n",
      "Time this epoch: 0.051696 seconds\n",
      "Time this epoch: 0.050667 seconds\n",
      "Time this epoch: 0.050678 seconds\n",
      "Time this epoch: 0.051070 seconds\n",
      "Time this epoch: 0.050709 seconds\n",
      "Time this epoch: 0.051261 seconds\n",
      "Time this epoch: 0.051146 seconds\n",
      "Time this epoch: 0.051129 seconds\n",
      "Time this epoch: 0.051038 seconds\n",
      "Time this epoch: 0.051087 seconds\n",
      "Time this epoch: 0.050975 seconds\n",
      "Time this epoch: 0.050918 seconds\n",
      "Time this epoch: 0.050715 seconds\n",
      "Time this epoch: 0.051067 seconds\n",
      "Time this epoch: 0.050750 seconds\n",
      "Time this epoch: 0.050903 seconds\n",
      "Time this epoch: 0.050980 seconds\n",
      "Time this epoch: 0.050959 seconds\n",
      "Time this epoch: 0.050914 seconds\n",
      "Time this epoch: 0.051897 seconds\n",
      "Time this epoch: 0.051732 seconds\n",
      "Time this epoch: 0.050553 seconds\n",
      "Time this epoch: 0.050522 seconds\n",
      "Time this epoch: 0.051605 seconds\n",
      "Time this epoch: 0.050705 seconds\n",
      "Time this epoch: 0.050709 seconds\n",
      "Time this epoch: 0.050877 seconds\n",
      "Time this epoch: 0.052455 seconds\n",
      "Time this epoch: 0.050546 seconds\n",
      "Time this epoch: 0.050484 seconds\n",
      "Time this epoch: 0.050949 seconds\n",
      "Time this epoch: 0.051007 seconds\n",
      "Time this epoch: 0.050785 seconds\n",
      "Time this epoch: 0.051064 seconds\n",
      "Time this epoch: 0.050880 seconds\n",
      "Time this epoch: 0.051014 seconds\n",
      "Time this epoch: 0.051135 seconds\n",
      "Time this epoch: 0.050858 seconds\n",
      "Time this epoch: 0.050878 seconds\n",
      "Time this epoch: 0.050924 seconds\n",
      "Time this epoch: 0.050625 seconds\n",
      "Time this epoch: 0.050647 seconds\n",
      "Time this epoch: 0.050721 seconds\n",
      "Time this epoch: 0.051308 seconds\n",
      "Time this epoch: 0.050811 seconds\n",
      "Time this epoch: 0.050768 seconds\n",
      "Time this epoch: 0.051402 seconds\n",
      "Time this epoch: 0.050671 seconds\n",
      "Time this epoch: 0.050547 seconds\n",
      "Time this epoch: 0.050865 seconds\n",
      "Time this epoch: 0.050864 seconds\n",
      "Time this epoch: 0.051072 seconds\n",
      "Time this epoch: 0.051019 seconds\n",
      "Time this epoch: 0.051181 seconds\n",
      "Time this epoch: 0.050569 seconds\n",
      "Time this epoch: 0.050888 seconds\n",
      "Time this epoch: 0.050959 seconds\n",
      "Time this epoch: 0.050987 seconds\n",
      "Time this epoch: 0.051007 seconds\n",
      "Time this epoch: 0.051018 seconds\n",
      "Time this epoch: 0.050787 seconds\n",
      "Time this epoch: 0.051025 seconds\n",
      "Time this epoch: 0.050876 seconds\n",
      "Time this epoch: 0.051119 seconds\n",
      "Time this epoch: 0.050690 seconds\n",
      "Time this epoch: 0.050889 seconds\n",
      "Time this epoch: 0.050750 seconds\n",
      "Time this epoch: 0.050918 seconds\n",
      "Time this epoch: 0.051138 seconds\n",
      "Time this epoch: 0.050907 seconds\n",
      "Time this epoch: 0.050947 seconds\n",
      "Time this epoch: 0.050700 seconds\n",
      "Time this epoch: 0.050580 seconds\n",
      "Time this epoch: 0.050678 seconds\n",
      "Time this epoch: 0.050746 seconds\n",
      "Time this epoch: 0.050823 seconds\n",
      "Time this epoch: 0.050784 seconds\n",
      "Time this epoch: 0.051287 seconds\n",
      "Time this epoch: 0.050831 seconds\n",
      "Time this epoch: 0.050845 seconds\n",
      "Time this epoch: 0.050758 seconds\n",
      "Time this epoch: 0.051086 seconds\n",
      "Time this epoch: 0.050784 seconds\n",
      "Time this epoch: 0.050970 seconds\n",
      "Time this epoch: 0.051242 seconds\n",
      "Time this epoch: 0.051388 seconds\n",
      "Time this epoch: 0.051076 seconds\n",
      "Time this epoch: 0.050969 seconds\n",
      "Time this epoch: 0.051065 seconds\n",
      "Time this epoch: 0.051293 seconds\n",
      "Time this epoch: 0.050908 seconds\n",
      "Time this epoch: 0.050979 seconds\n",
      "Time this epoch: 0.052359 seconds\n",
      "Time this epoch: 0.051964 seconds\n",
      "Time this epoch: 0.050935 seconds\n",
      "Time this epoch: 0.051033 seconds\n",
      "Time this epoch: 0.050673 seconds\n",
      "Time this epoch: 0.050794 seconds\n",
      "Time this epoch: 0.050563 seconds\n",
      "Time this epoch: 0.051012 seconds\n",
      "Time this epoch: 0.051474 seconds\n",
      "Time this epoch: 0.052148 seconds\n",
      "Time this epoch: 0.052616 seconds\n",
      "Time this epoch: 0.051386 seconds\n",
      "Time this epoch: 0.052591 seconds\n",
      "Time this epoch: 0.051713 seconds\n",
      "Time this epoch: 0.051499 seconds\n",
      "Time this epoch: 0.051261 seconds\n",
      "Time this epoch: 0.051426 seconds\n",
      "Time this epoch: 0.051230 seconds\n",
      "Time this epoch: 0.051014 seconds\n",
      "Time this epoch: 0.051030 seconds\n",
      "Time this epoch: 0.050938 seconds\n",
      "Time this epoch: 0.052426 seconds\n",
      "Time this epoch: 0.053640 seconds\n",
      "Time this epoch: 0.051332 seconds\n",
      "Time this epoch: 0.054775 seconds\n",
      "Time this epoch: 0.051418 seconds\n",
      "Time this epoch: 0.050937 seconds\n",
      "Time this epoch: 0.050558 seconds\n",
      "Time this epoch: 0.050654 seconds\n",
      "Time this epoch: 0.050916 seconds\n",
      "Time this epoch: 0.050826 seconds\n",
      "Time this epoch: 0.050848 seconds\n",
      "Time this epoch: 0.050832 seconds\n",
      "Time this epoch: 0.050887 seconds\n",
      "Time this epoch: 0.050839 seconds\n",
      "Time this epoch: 0.051138 seconds\n",
      "Time this epoch: 0.050957 seconds\n",
      "Time this epoch: 0.050958 seconds\n",
      "Time this epoch: 0.050886 seconds\n",
      "Time this epoch: 0.051032 seconds\n",
      "Time this epoch: 0.050906 seconds\n",
      "Time this epoch: 0.050970 seconds\n",
      "Time this epoch: 0.050988 seconds\n",
      "Time this epoch: 0.050895 seconds\n",
      "Time this epoch: 0.050839 seconds\n",
      "Time this epoch: 0.050890 seconds\n",
      "Time this epoch: 0.050972 seconds\n",
      "Time this epoch: 0.051056 seconds\n",
      "Time this epoch: 0.051295 seconds\n",
      "Time this epoch: 0.050919 seconds\n",
      "Time this epoch: 0.050770 seconds\n",
      "Time this epoch: 0.050874 seconds\n",
      "Time this epoch: 0.050397 seconds\n",
      "Time this epoch: 0.050789 seconds\n",
      "Time this epoch: 0.050754 seconds\n",
      "Time this epoch: 0.050691 seconds\n",
      "Time this epoch: 0.050547 seconds\n",
      "Time this epoch: 0.050990 seconds\n",
      "Time this epoch: 0.050561 seconds\n",
      "Time this epoch: 0.050810 seconds\n",
      "Time this epoch: 0.050729 seconds\n",
      "Time this epoch: 0.050848 seconds\n",
      "Time this epoch: 0.050760 seconds\n",
      "Time this epoch: 0.051109 seconds\n",
      "Time this epoch: 0.050849 seconds\n",
      "Time this epoch: 0.051100 seconds\n",
      "Time this epoch: 0.050854 seconds\n",
      "Time this epoch: 0.051072 seconds\n",
      "Time this epoch: 0.050754 seconds\n",
      "Time this epoch: 0.050898 seconds\n",
      "Time this epoch: 0.051155 seconds\n",
      "Time this epoch: 0.051033 seconds\n",
      "Time this epoch: 0.051622 seconds\n",
      "Time this epoch: 0.051074 seconds\n",
      "Time this epoch: 0.051210 seconds\n",
      "Time this epoch: 0.051329 seconds\n",
      "Time this epoch: 0.051144 seconds\n",
      "Time this epoch: 0.050582 seconds\n",
      "Time this epoch: 0.050891 seconds\n",
      "Time this epoch: 0.050840 seconds\n",
      "Time this epoch: 0.050674 seconds\n",
      "Time this epoch: 0.050664 seconds\n",
      "Time this epoch: 0.051784 seconds\n",
      "Time this epoch: 0.050982 seconds\n",
      "Time this epoch: 0.050822 seconds\n",
      "Time this epoch: 0.050899 seconds\n",
      "Time this epoch: 0.051303 seconds\n",
      "Time this epoch: 0.051402 seconds\n",
      "Time this epoch: 0.050968 seconds\n",
      "Time this epoch: 0.051160 seconds\n",
      "Time this epoch: 0.050730 seconds\n",
      "Time this epoch: 0.051023 seconds\n",
      "Time this epoch: 0.051046 seconds\n",
      "Time this epoch: 0.051432 seconds\n",
      "Time this epoch: 0.051320 seconds\n",
      "Time this epoch: 0.051399 seconds\n",
      "Time this epoch: 0.051864 seconds\n",
      "Time this epoch: 0.052006 seconds\n",
      "Time this epoch: 0.050634 seconds\n",
      "Time this epoch: 0.050942 seconds\n",
      "Time this epoch: 0.050522 seconds\n",
      "Time this epoch: 0.051037 seconds\n",
      "Time this epoch: 0.050992 seconds\n",
      "Time this epoch: 0.051161 seconds\n",
      "Time this epoch: 0.050994 seconds\n",
      "Time this epoch: 0.051320 seconds\n",
      "Time this epoch: 0.051008 seconds\n",
      "Time this epoch: 0.051133 seconds\n",
      "Time this epoch: 0.050679 seconds\n",
      "Time this epoch: 0.050777 seconds\n",
      "Time this epoch: 0.050722 seconds\n",
      "Time this epoch: 0.051235 seconds\n",
      "Time this epoch: 0.050998 seconds\n",
      "Time this epoch: 0.050904 seconds\n",
      "Time this epoch: 0.050987 seconds\n",
      "Time this epoch: 0.050939 seconds\n",
      "Time this epoch: 0.051087 seconds\n",
      "Time this epoch: 0.050918 seconds\n",
      "Time this epoch: 0.050949 seconds\n",
      "Time this epoch: 0.051081 seconds\n",
      "Time this epoch: 0.051911 seconds\n",
      "Time this epoch: 0.051513 seconds\n",
      "Time this epoch: 0.050730 seconds\n",
      "Time this epoch: 0.050905 seconds\n",
      "Time this epoch: 0.050670 seconds\n",
      "Time this epoch: 0.050511 seconds\n",
      "Time this epoch: 0.050698 seconds\n",
      "Time this epoch: 0.050878 seconds\n",
      "Time this epoch: 0.050670 seconds\n",
      "Time this epoch: 0.050777 seconds\n",
      "Time this epoch: 0.050635 seconds\n",
      "Time this epoch: 0.050559 seconds\n",
      "Time this epoch: 0.051045 seconds\n",
      "Time this epoch: 0.050802 seconds\n",
      "Time this epoch: 0.050666 seconds\n",
      "Time this epoch: 0.050967 seconds\n",
      "Time this epoch: 0.050630 seconds\n",
      "Time this epoch: 0.051605 seconds\n",
      "Time this epoch: 0.050664 seconds\n",
      "Time this epoch: 0.050956 seconds\n",
      "Time this epoch: 0.051211 seconds\n",
      "Time this epoch: 0.051472 seconds\n",
      "Time this epoch: 0.051320 seconds\n",
      "Time this epoch: 0.051104 seconds\n",
      "Time this epoch: 0.051876 seconds\n",
      "Time this epoch: 0.051000 seconds\n",
      "Time this epoch: 0.050783 seconds\n",
      "Time this epoch: 0.051126 seconds\n",
      "Time this epoch: 0.051226 seconds\n",
      "Time this epoch: 0.051286 seconds\n",
      "Time this epoch: 0.051183 seconds\n",
      "Time this epoch: 0.050921 seconds\n",
      "Time this epoch: 0.050759 seconds\n",
      "Time this epoch: 0.050864 seconds\n",
      "Time this epoch: 0.050864 seconds\n",
      "Time this epoch: 0.051285 seconds\n",
      "Time this epoch: 0.050610 seconds\n",
      "Time this epoch: 0.050779 seconds\n",
      "Time this epoch: 0.050874 seconds\n",
      "Time this epoch: 0.051100 seconds\n",
      "Time this epoch: 0.050483 seconds\n",
      "Time this epoch: 0.050688 seconds\n",
      "Time this epoch: 0.050510 seconds\n",
      "Time this epoch: 0.050744 seconds\n",
      "Time this epoch: 0.050418 seconds\n",
      "Time this epoch: 0.050919 seconds\n",
      "Time this epoch: 0.050759 seconds\n",
      "Time this epoch: 0.050832 seconds\n",
      "Time this epoch: 0.050345 seconds\n",
      "Time this epoch: 0.050819 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-f4332f2e11d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtrain_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/temp/pylearn2/pylearn2/train.pyc\u001b[0m in \u001b[0;36mmain_loop\u001b[1;34m(self, time_budget)\u001b[0m\n\u001b[0;32m    213\u001b[0m                                          \"continues.\")\n\u001b[0;32m    214\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                     \u001b[0mextension_continue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_callbacks_and_monitoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_epochs_seen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/temp/pylearn2/pylearn2/train.pyc\u001b[0m in \u001b[0;36mrun_callbacks_and_monitoring\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[0mextension\u001b[0m \u001b[0mwants\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstop\u001b[0m \u001b[0mlearning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \"\"\"\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[0mcontinue_learning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/temp/pylearn2/pylearn2/monitor.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m                     \u001b[1;31m# X is a flat (not nested) tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_prereqs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m                     \u001b[0ma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m                     \u001b[0mactual_ne\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_data_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[1;31m# end for X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/temp/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not firstrun:\n",
    "    model.monitor.disable_logging()\n",
    "\n",
    "firstrun = False\n",
    "monitor.req_sock.close()\n",
    "monitor.pub_sock.close()\n",
    "monitor = live_monitoring.LiveMonitoring()\n",
    "\n",
    "h0 = mlp.Sigmoid(layer_name='h0', dim=400, irange=.05) #9\n",
    "h1 = mlp.Sigmoid(layer_name='h1', dim=400, irange=.05) #18\n",
    "ylayer = mlp.Linear(layer_name='y', dim=1, irange=.05)\n",
    "\n",
    "layers = [h0, h1, ylayer]\n",
    "model = mlp.MLP(layers, nvis=9)\n",
    "\n",
    "monitoring = dict(valid=valid, train=train_monitor)\n",
    "termination = EpochCounter(10000)\n",
    "extensions = [monitor]\n",
    "\n",
    "algorithm = sgd.SGD(.001, batch_size=100, #cost=Dropout(.8),\n",
    "                     monitoring_dataset = monitoring, termination_criterion = termination)\n",
    "\n",
    "train_job = Train(train, model, algorithm, extensions=extensions)\n",
    "\n",
    "\n",
    "train_job.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"zackmodel2.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(model, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 9] Bad file descriptor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-43914426d2d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"zackmodelc.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m: [Errno 9] Bad file descriptor"
     ]
    }
   ],
   "source": [
    "with open(r\"zackmodelc.pickle\", \"rb\") as output_file:\n",
    "    model = pickle.load(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "0.5\n",
      "test set\n",
      "0.5\n",
      "training set\n",
      "0.5\n",
      "test set\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "X = T.matrix()\n",
    "X = model.get_input_space().make_theano_batch()\n",
    "Y = model.fprop(X)\n",
    "f = function([X], Y)\n",
    "\n",
    "def compare(x, y, set_name, shuffle=False):\n",
    "    x = copy.deepcopy(x)\n",
    "    y = copy.deepcopy(y)\n",
    "    if shuffle:\n",
    "        numpy.random.shuffle(y)\n",
    "    test = f(x)\n",
    "\n",
    "    comparison = zip(y, test)\n",
    "\n",
    "    print set_name\n",
    "    for i in range(1):\n",
    "        right = 0\n",
    "        for row in comparison:\n",
    "            if float(row[0][i]) * float(row[1][i]) > 0:\n",
    "                right += 1\n",
    "        print right/float(len(x))\n",
    "        \n",
    "compare(X_train, Y_train, \"training set\")\n",
    "compare(X_test, Y_test, \"test set\")\n",
    "compare(X_train, Y_train,  \"training set\", True)\n",
    "compare(X_test, Y_test, \"test set\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-85-5a7ccd4f90b6>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-85-5a7ccd4f90b6>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Training set\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ben;s\n",
    "Training set\n",
    "0.518590998043\n",
    "0.526139222812\n",
    "0.51607492312\n",
    "test set\n",
    "0.0542353927873\n",
    "0.0539558289069\n",
    "0.0567514677104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random\n",
    "0.477774671512\n",
    "0.476376852111\n",
    "0.474326716988\n",
    "\n",
    "0.519280205656\n",
    "0.517994858612\n",
    "0.510711225364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "up = 0\n",
    "down = 0\n",
    "\n",
    "for x in range(0, 1):\n",
    "    for row in Y_train:\n",
    "\n",
    "        if float(row[x]) > 0:\n",
    "            up += 1\n",
    "        else:\n",
    "            down += 1\n",
    "\n",
    "\n",
    "    print up /(down + up)\n",
    "    \n",
    "up = 0\n",
    "down = 0\n",
    "\n",
    "for x in range(0, 1):\n",
    "    for row in Y_test:\n",
    "\n",
    "        if float(row[x]) > 0:\n",
    "            up += 1\n",
    "        else:\n",
    "            down += 1\n",
    "\n",
    "\n",
    "    print up /(down + up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set\n",
      "13.0 0.0442116\n",
      "15.0 0.0442635\n",
      "-4.0 0.0442605\n",
      "0.8 0.0441946\n",
      "-10.1 0.0441494\n",
      "-2.0 0.0442702\n",
      "3.6 0.0441517\n",
      "-3.0 0.0441133\n",
      "-5.0 0.0441454\n",
      "3.6 0.0441767\n",
      "7.0 0.0442566\n",
      "14.0 0.0441935\n",
      "16.0 0.0441824\n",
      "-3.0 0.0442591\n",
      "-14.0 0.0441659\n",
      "23.0 0.0441274\n",
      "-7.0 0.0440848\n",
      "8.0 0.0441587\n",
      "-3.0 0.0440734\n",
      "-7.5 0.0441959\n",
      "-2.0 0.0441687\n",
      "2.5 0.0441367\n",
      "-7.0 0.0441941\n",
      "1.9 0.0441543\n",
      "-1.0 0.0441918\n",
      "-2.7 0.0442283\n",
      "-9.0 0.0440423\n",
      "1.0 0.0442788\n",
      "-30.0 0.0439829\n",
      "-5.0 0.0442195\n",
      "-4.0 0.0442209\n",
      "4.0 0.0441351\n",
      "2.0 0.0441611\n",
      "18.8 0.0441827\n",
      "-12.0 0.044165\n",
      "-3.0 0.0442467\n",
      "-2.0 0.0439934\n",
      "-11.0 0.0441413\n",
      "16.0 0.0441942\n",
      "2.0 0.0441681\n",
      "7.1 0.0441967\n",
      "-1.0 0.0441165\n",
      "1.3 0.044179\n",
      "5.0 0.0441355\n",
      "-10.0 0.0442595\n",
      "-8.0 0.0440662\n",
      "-1.7 0.0441614\n",
      "-9.7 0.0441512\n",
      "4.6 0.0441411\n",
      "9.0 0.0442101\n",
      "74.0 0.0441366\n",
      "15.0 0.0442519\n",
      "20.0 0.0441996\n",
      "-1.0 0.0441824\n",
      "-5.0 0.0440073\n",
      "-6.0 0.0440683\n",
      "14.8 0.0443168\n",
      "-1.0 0.0442654\n",
      "9.0 0.0441825\n",
      "3.0 0.0441502\n",
      "3.7 0.044195\n",
      "-15.6 0.0442085\n",
      "3.2 0.0441423\n",
      "-3.0 0.044272\n",
      "-8.0 0.0440116\n",
      "-3.0 0.0440861\n",
      "-0.4 0.0441553\n",
      "-5.0 0.0441993\n",
      "0.5 0.0441477\n",
      "-11.0 0.0441698\n",
      "-11.0 0.0442363\n",
      "5.9 0.0442143\n",
      "-1.6 0.044192\n",
      "11.0 0.0441515\n",
      "4.0 0.0442675\n",
      "0.5 0.0441933\n",
      "-4.0 0.0439839\n",
      "4.4 0.0441349\n",
      "3.0 0.0442\n",
      "-1.0 0.0442047\n",
      "-6.0 0.0441871\n",
      "-1.9 0.0442329\n",
      "-21.0 0.0440686\n",
      "-2.5 0.0442104\n",
      "20.0 0.0441812\n",
      "-2.0 0.0442238\n",
      "-3.0 0.044174\n",
      "-42.0 0.0442238\n",
      "-10.0 0.0440864\n",
      "-15.5 0.04418\n",
      "10.0 0.0442037\n",
      "-12.0 0.0441437\n",
      "-4.0 0.0441898\n",
      "-5.0 0.0441379\n",
      "-36.0 0.0441738\n",
      "-4.1 0.0441824\n",
      "2.0 0.0442162\n",
      "27.0 0.0440865\n",
      "-0.1 0.0441797\n",
      "12.5 0.0441825\n",
      "8.0 0.0442181\n",
      "3.0 0.0442607\n",
      "13.0 0.0441138\n",
      "-10.1 0.0442214\n",
      "-0.1 0.0441816\n",
      "-18.0 0.0440743\n",
      "-19.0 0.0440107\n",
      "-6.0 0.0442207\n",
      "-2.1 0.0442472\n",
      "1.4 0.0441681\n",
      "-9.0 0.0440785\n",
      "-17.8 0.0442458\n",
      "2.0 0.0442299\n",
      "-18.0 0.0440939\n",
      "1.5 0.0441863\n",
      "-5.2 0.0441937\n",
      "-1.3 0.0441723\n",
      "3.0 0.0442262\n",
      "21.0 0.0441819\n",
      "12.7 0.0441726\n",
      "-8.3 0.044185\n",
      "2.0 0.0440955\n",
      "16.0 0.0442159\n",
      "-8.0 0.0441627\n",
      "-28.0 0.0441415\n",
      "-34.2 0.0442506\n",
      "7.0 0.0441387\n",
      "9.0 0.0442217\n",
      "-1.0 0.0441369\n",
      "2.0 0.044118\n",
      "-6.0 0.0442287\n",
      "-8.0 0.0441921\n",
      "-14.0 0.0442732\n",
      "14.0 0.0441814\n",
      "-3.9 0.0441983\n",
      "-18.0 0.0442539\n",
      "-15.0 0.0439813\n",
      "-1.0 0.0442596\n",
      "-1.0 0.0440517\n",
      "-0.3 0.0442434\n",
      "-6.0 0.0440677\n",
      "5.0 0.0442116\n",
      "19.0 0.0442172\n",
      "3.0 0.044187\n",
      "1.0 0.0440705\n",
      "1.5 0.0441461\n",
      "-7.0 0.0441504\n",
      "-1.3 0.0441965\n",
      "3.0 0.0440727\n",
      "-11.0 0.0441398\n",
      "-41.0 0.0442276\n",
      "3.0 0.0442526\n",
      "23.0 0.0441466\n",
      "1.0 0.0442733\n",
      "7.0 0.0440802\n",
      "7.0 0.044078\n",
      "-11.0 0.0442376\n",
      "6.0 0.044084\n",
      "0.4 0.0441624\n",
      "1.0 0.0440777\n",
      "6.0 0.0439885\n",
      "31.5 0.0441575\n",
      "23.0 0.0440557\n",
      "32.0 0.0441303\n",
      "4.0 0.0442142\n",
      "-21.4 0.0442218\n",
      "-3.0 0.0441189\n",
      "2.8 0.0441939\n",
      "-4.0 0.0442356\n",
      "-26.0 0.0441261\n",
      "12.0 0.0441036\n",
      "-6.0 0.0440813\n",
      "-18.0 0.0440807\n",
      "-2.0 0.0441887\n",
      "1.1 0.0442056\n",
      "8.5 0.0441407\n",
      "-6.0 0.0442063\n",
      "35.0 0.0439912\n",
      "-5.0 0.0441414\n",
      "0.4 0.0442312\n",
      "-19.0 0.0440881\n",
      "16.0 0.0441388\n",
      "6.6 0.0441954\n",
      "4.0 0.0442157\n",
      "-2.4 0.0441822\n",
      "7.0 0.0439835\n",
      "1.0 0.0439838\n",
      "-1.0 0.0442267\n",
      "-20.0 0.0441674\n",
      "39.0 0.0442163\n",
      "3.0 0.0442004\n",
      "4.5 0.0442561\n",
      "2.0 0.0442764\n",
      "1.0 0.0440883\n",
      "-22.0 0.0442466\n",
      "-19.0 0.0440922\n",
      "-14.0 0.0442757\n",
      "-8.8 0.0441788\n",
      "-5.0 0.0441043\n",
      "2.0 0.044078\n",
      "-10.0 0.04424\n",
      "12.5 0.0442225\n",
      "-6.0 0.044195\n",
      "4.0 0.0442181\n",
      "13.0 0.0442441\n",
      "-28.0 0.0441884\n",
      "-3.4 0.0442035\n",
      "6.8 0.0441978\n",
      "2.0 0.0442597\n",
      "1.0 0.0442561\n",
      "2.0 0.0441644\n",
      "1.3 0.0442101\n",
      "11.0 0.0440952\n",
      "21.5 0.0441857\n",
      "-12.0 0.044131\n",
      "4.8 0.044233\n",
      "-8.8 0.0441922\n",
      "-7.4 0.0441479\n",
      "-10.9 0.0442956\n",
      "-7.0 0.044203\n",
      "28.0 0.043998\n",
      "-5.7 0.0441443\n",
      "31.0 0.0441576\n",
      "2.0 0.0442466\n",
      "-1.3 0.0441416\n",
      "14.0 0.0440121\n",
      "6.0 0.0442088\n",
      "2.0 0.0441432\n",
      "18.7 0.0442424\n",
      "-9.2 0.0441978\n",
      "17.0 0.0442593\n",
      "10.0 0.0440662\n",
      "5.0 0.044156\n",
      "4.0 0.0442132\n",
      "13.0 0.044269\n",
      "7.0 0.0442309\n",
      "4.0 0.0441461\n",
      "15.0 0.0442302\n",
      "-11.6 0.0443119\n",
      "1.0 0.0441494\n",
      "7.0 0.0442283\n",
      "9.0 0.0441839\n",
      "-1.0 0.0440532\n",
      "0.3 0.044157\n",
      "2.0 0.0441629\n",
      "3.0 0.044159\n",
      "-15.0 0.0440806\n",
      "15.0 0.0440826\n",
      "8.0 0.0441391\n",
      "-4.9 0.0441433\n",
      "5.3 0.0441502\n",
      "-0.2 0.0442444\n",
      "12.4 0.0442457\n",
      "7.0 0.0441604\n",
      "6.0 0.0441366\n",
      "0.9 0.0441784\n",
      "0.7 0.0442726\n",
      "9.0 0.0439843\n",
      "-9.0 0.0439918\n",
      "-4.0 0.0440964\n",
      "0.1 0.0442371\n",
      "-2.0 0.0442545\n",
      "-1.0 0.0442071\n",
      "-15.0 0.04404\n",
      "3.0 0.044187\n",
      "-13.0 0.0442048\n",
      "-1.0 0.0441885\n",
      "20.0 0.0441765\n",
      "1.0 0.0440137\n",
      "25.0 0.0441314\n",
      "4.0 0.0441733\n",
      "35.0 0.0442811\n",
      "-5.0 0.0441582\n",
      "1.0 0.0442668\n",
      "9.0 0.044045\n",
      "7.3 0.044171\n",
      "-6.0 0.0440909\n",
      "9.0 0.0440987\n",
      "-1.0 0.0440774\n",
      "-2.0 0.0441459\n",
      "-7.0 0.0442412\n",
      "-63.0 0.0441045\n",
      "-1.5 0.0441546\n",
      "-1.0 0.0442662\n",
      "12.0 0.0441733\n",
      "-14.6 0.0441896\n",
      "-2.6 0.0442466\n",
      "24.0 0.044249\n",
      "-9.3 0.0442168\n",
      "-46.0 0.0440018\n",
      "11.0 0.0441422\n",
      "-13.0 0.044176\n",
      "-2.0 0.0442259\n",
      "-1.0 0.0442114\n",
      "2.0 0.044289\n",
      "0.7 0.0441392\n",
      "-2.0 0.0442245\n",
      "-16.0 0.0440793\n",
      "18.0 0.0442567\n",
      "-1.0 0.0441075\n",
      "-6.0 0.0441603\n",
      "-21.8 0.0442439\n",
      "-1.0 0.0442194\n",
      "12.0 0.0439882\n",
      "4.0 0.0441768\n",
      "5.0 0.0440826\n",
      "5.0 0.0440784\n",
      "10.0 0.0440029\n",
      "-4.0 0.0439844\n",
      "-3.0 0.0442452\n",
      "-1.0 0.0441182\n",
      "-0.5 0.0441499\n",
      "18.0 0.0442259\n",
      "4.0 0.044188\n",
      "-18.0 0.0442635\n",
      "0.3 0.0441385\n",
      "-3.0 0.0441303\n",
      "15.0 0.0439999\n",
      "4.2 0.0441488\n",
      "-16.0 0.0441532\n",
      "9.0 0.0441811\n",
      "0.7 0.0441677\n",
      "-1.0 0.0442246\n",
      "-4.0 0.044225\n",
      "-7.0 0.0441927\n",
      "-3.0 0.0440911\n",
      "-3.1 0.0441595\n",
      "-8.0 0.0441039\n",
      "2.6 0.0442051\n",
      "8.0 0.0440568\n",
      "-15.0 0.0442156\n",
      "1.0 0.044243\n",
      "-1.0 0.044266\n",
      "7.0 0.0440432\n",
      "4.0 0.0441648\n",
      "-13.0 0.044008\n",
      "-36.0 0.0442019\n",
      "9.0 0.0441387\n",
      "4.0 0.0439898\n",
      "-3.0 0.044265\n",
      "-5.5 0.0442315\n",
      "-6.0 0.0441302\n",
      "-2.0 0.0441898\n",
      "4.0 0.0441944\n",
      "-3.0 0.044254\n",
      "-8.0 0.0441194\n",
      "13.0 0.0442282\n",
      "3.1 0.0441805\n",
      "-2.5 0.04419\n",
      "7.8 0.0442325\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "X = T.matrix()\n",
    "X = model.get_input_space().make_theano_batch()\n",
    "Y = model.fprop(X)\n",
    "f = function([X], Y)\n",
    "\n",
    "def compare(x, y, set_name, shuffle=False):\n",
    "    x = copy.deepcopy(x)\n",
    "    y = copy.deepcopy(y)\n",
    "    if shuffle:\n",
    "        numpy.random.shuffle(y)\n",
    "    test = f(x)\n",
    "\n",
    "    comparison = zip(y, test)\n",
    "    numpy.random.shuffle(comparison)\n",
    "    print set_name\n",
    "    for i in range(1):\n",
    "        right = 0\n",
    "        for row in comparison:\n",
    "            print row[0][i] , row[1][i]\n",
    "            if float(row[0][i]) * float(row[1][i]) >= 0:\n",
    "                right += 1\n",
    "        print right/float(len(x))\n",
    "        \n",
    "compare(X_test, Y_test, \"test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#monitoring = dict(valid=valid)\n",
    "monitoring = dict()\n",
    "#termination = MonitorBased(channel_name=\"valid_y_misclass\", N=100)\n",
    "termination = EpochCounter(10)\n",
    "#extensions = [best_params.MonitorBasedSaveBest(channel_name=\"valid_y_misclass\",\n",
    "#save_path=\"train_best.pkl\"), monitor]\n",
    "extensions = [monitor]\n",
    "\n",
    "\n",
    "algorithm = sgd.SGD(0.1, batch_size=100, cost=Dropout(),\n",
    "                    monitoring_dataset = monitoring, termination_criterion = termination)\n",
    "\n",
    "save_path = \"train_bes3t.pkl\"\n",
    "#if os.path.exists(save_path):\n",
    "#    model = serial.load(save_path)\n",
    "#else:\n",
    "#    print 'Running training'\n",
    "#    train_job = Train(train, model, algorithm, extensions=extensions, save_path=\"train.pkl\", save_freq=1)\n",
    "#    train_job.main_loop()\n",
    "\n",
    "train_job = Train(train, model, algorithm, extensions=extensions, save_path=\"train.pkl\", save_freq=1)\n",
    "train_job.main_loop()\n",
    "\n",
    "\n",
    "#X = model.get_input_space().make_batch_theano()\n",
    "#Y = model.fprop(X)\n",
    "\n",
    "#y = T.argmax(Y, axis=1)\n",
    "#f = function([X], y)\n",
    "#yhat = f(test.X)\n",
    "\n",
    "#y = np.where(test.get_targets())[1]\n",
    "#print 'accuracy', (y==yhat).sum() / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pybrain\n",
    "import numpy as np\n",
    "from pybrain.structure import FeedForwardNetwork\n",
    "from pybrain.structure import LinearLayer, SigmoidLayer\n",
    "from pybrain.structure import FullConnection\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import random\n",
    "import ast\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import glob\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import pprint\n",
    "import re\n",
    "from sklearn import linear_model, datasets\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn import svm\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import gevent.monkey\n",
    "gevent.monkey.patch_socket()\n",
    "import numpy\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy import event\n",
    "from sqlalchemy.dialects.mysql import LONGTEXT\n",
    "import sqlite3\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import *\n",
    "import urllib2\n",
    "import urllib\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser\n",
    "import gevent\n",
    "import datetime\n",
    "import marshal\n",
    "from pylearn2.datasets.dense_design_matrix import DenseDesignMatrix\n",
    "\n",
    "from __future__ import division\n",
    "import os\n",
    "\n",
    "import pylearn2\n",
    "import numpy as np\n",
    "from pylearn2.train import Train\n",
    "from pylearn2.datasets.mnist import MNIST\n",
    "from pylearn2.models import softmax_regression, mlp, svm\n",
    "from pylearn2.training_algorithms import bgd, sgd\n",
    "from pylearn2.termination_criteria import MonitorBased, EpochCounter\n",
    "from pylearn2.train_extensions import best_params, live_monitoring\n",
    "from pylearn2.utils import serial\n",
    "from pylearn2.costs.mlp.dropout import Dropout\n",
    "from pylearn2.costs.mlp import WeightDecay\n",
    "from theano import function\n",
    "from theano import tensor as T\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"network.pkl\", \"rb\") as input_file:\n",
    "    model = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainfile = open('usd_eur_trainingdata.csv', 'r')\n",
    "testfile = open('usd_eur_testingdata.csv', 'r')\n",
    "\n",
    "train, test = [], []\n",
    "for line in trainfile:\n",
    "    line = line.strip().split(',')\n",
    "    features = line[:-3]\n",
    "    outputs = line[-3:]\n",
    "    train.append([features, outputs])\n",
    "\n",
    "for line in testfile:\n",
    "    line = line.strip().split(',')\n",
    "    features = line[:-3]\n",
    "    outputs = line[-3:]\n",
    "    test.append([features, outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset of 3577 samples.\n",
      "Test set of 389 samples.\n"
     ]
    }
   ],
   "source": [
    "ds = SupervisedDataSet(9, 3)\n",
    "for t in train:\n",
    "    ds.addSample(t[0], t[1])\n",
    "print \"Dataset of \" + str(len(ds)) + \" samples.\"\n",
    "print \"Test set of \" + str(len(test)) + \" samples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset of 3577 samples.\n",
      "Test set of 389 samples.\n"
     ]
    }
   ],
   "source": [
    "ds = SupervisedDataSet(9, 3)\n",
    "for t in train:\n",
    "    ds.addSample(t[0], t[1])\n",
    "print \"Dataset of \" + str(len(ds)) + \" samples.\"\n",
    "print \"Test set of \" + str(len(test)) + \" samples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-70aa8eba2fe2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0minput_size\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "\n",
    "from math import sqrt\n",
    "from pybrain.datasets.supervised import SupervisedDataSet as SDS\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "test_file = 'usd_eur_testingdata.csv'\n",
    "model_file = 'network.pkl'\n",
    "output_predictions_file = 'predictions.txt'\n",
    "\n",
    "# load model\n",
    "\n",
    "net = pickle.load( open( model_file, 'rb' ))\n",
    "\n",
    "# load data\n",
    "\n",
    "test = np.loadtxt( test_file, delimiter = ',' )\n",
    "x_test = test[:,0:-1]\n",
    "y_test = test[:,-1]\n",
    "y_test = y_test.reshape( -1, 1 )\n",
    "\n",
    "# you'll need labels. In case you don't have them...\n",
    "y_test_dummy = np.zeros( y_test.shape )\n",
    "\n",
    "input_size = x_test.shape[1]\n",
    "target_size = y_test.shape[1]\n",
    "\n",
    "assert( net.indim == input_size )\n",
    "assert( net.outdim == target_size )\n",
    "\n",
    "# prepare dataset\n",
    "\n",
    "ds = SDS( input_size, target_size )\n",
    "ds.setField( 'input', x_test )\n",
    "ds.setField( 'target', y_test_dummy )\n",
    "\n",
    "# predict\n",
    "\n",
    "p = net.activateOnDataset( ds )\n",
    "\t\n",
    "mse = MSE( y_test, p )\n",
    "rmse = sqrt( mse )\n",
    "\n",
    "print \"testing RMSE:\", rmse\n",
    "\n",
    "np.savetxt( output_predictions_file, p, fmt = '%.6f' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainfile = open('usd_eur_trainingdata.csv', 'r')\n",
    "testfile = open('usd_eur_testingdata.csv', 'r')\n",
    "\n",
    "train, test = [], []\n",
    "for line in trainfile:\n",
    "    line = line.strip().split(',')\n",
    "    features = line[:-3]\n",
    "    outputs = line[-3:]\n",
    "    train.append([features, outputs])\n",
    "\n",
    "for line in testfile:\n",
    "    line = line.strip().split(',')\n",
    "    features = line[:-3]\n",
    "    outputs = line[-3:]\n",
    "    test.append([features, outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset of 3577 samples.\n",
      "Test set of 389 samples.\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "ds = SupervisedDataSet(9, 3)\n",
    "for t in train:\n",
    "    ds.addSample(t[0], t[1])\n",
    "print \"Dataset of \" + str(len(ds)) + \" samples.\"\n",
    "print \"Test set of \" + str(len(test)) + \" samples.\"\n",
    "\n",
    "\n",
    "p = net.activateOnDataset( ds )\n",
    "\n",
    "print type(p)\n",
    "\n",
    "np.savetxt( output_predictions_file, p, fmt = '%.6f' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainfile = open('usd_eur_trainingdata.csv', 'r')\n",
    "testfile = open('usd_eur_testingdata.csv', 'r')\n",
    "\n",
    "train_out, test_out = [], []\n",
    "for line in trainfile:\n",
    "    line = line.strip().split(',')\n",
    "    outputs = line[-3:]\n",
    "    train_out.append(outputs)\n",
    "\n",
    "for line in testfile:\n",
    "    line = line.strip().split(',')\n",
    "    outputs = line[-3:]\n",
    "    test_out.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comparison = zip(train_out, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "0.518590998043\n",
      "0.526139222812\n",
      "0.51607492312\n",
      "test set\n",
      "0.0542353927873\n",
      "0.0539558289069\n",
      "0.0567514677104\n"
     ]
    }
   ],
   "source": [
    "ds = SupervisedDataSet(9, 3)\n",
    "for t in train:\n",
    "    ds.addSample(t[0], t[1])\n",
    "\n",
    "p = net.activateOnDataset( ds )\n",
    "\n",
    "\n",
    "comparison = zip(train_out, p)\n",
    "\n",
    "\n",
    "print \"Training set\"\n",
    "for i in range(3):\n",
    "    right = 0\n",
    "    for row in comparison:\n",
    "        if float(row[0][i]) * float(row[1][i]) >= 0:\n",
    "            right += 1\n",
    "    print right/float(len(p))\n",
    "    \n",
    "\n",
    "    \n",
    "ds = SupervisedDataSet(9, 3)\n",
    "for t in test:\n",
    "    ds.addSample(t[0], t[1])\n",
    "    \n",
    "comparison = zip(test_out, p)\n",
    "\n",
    "print \"test set\"\n",
    "for i in range(3):\n",
    "    right = 0\n",
    "    for row in comparison:\n",
    "        if float(row[0][i]) * float(row[1][i]) >= 0:\n",
    "            right += 1\n",
    "    print right/float(len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainfile = open('usd_eur_trainingdata.csv', 'r')\n",
    "testfile = open('usd_eur_testingdata.csv', 'r')\n",
    "\n",
    "train_all, test_all = [], []\n",
    "for line in trainfile:\n",
    "    train_all.append(line.strip().split(','))\n",
    "\n",
    "for line in testfile:\n",
    "\n",
    "    test_all.append(line.strip().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_up_down(x, y):\n",
    "    samples = zip(x, y)\n",
    "    numpy.random.shuffle(samples)\n",
    "    up = []\n",
    "    down = []\n",
    "    for item in samples:\n",
    "        if item[1][0] > 0:\n",
    "            up.append(item)\n",
    "        elif item[1][0] < 0:\n",
    "            down.append(item)\n",
    "    min_length = min(len(up), len(down))\n",
    "    out = up[:min_length] + down[:min_length]\n",
    "    numpy.random.shuffle(out)\n",
    "    return zip(*out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.477774671512\n",
      "0.476376852111\n",
      "0.474326716988\n",
      "0.519280205656\n",
      "0.517994858612\n",
      "0.510711225364\n"
     ]
    }
   ],
   "source": [
    "up = 0\n",
    "down = 0\n",
    "\n",
    "for x in range(9, 12):\n",
    "    for row in train_all:\n",
    "\n",
    "        if float(row[x]) > 0:\n",
    "            up += 1\n",
    "        else:\n",
    "            down += 1\n",
    "\n",
    "\n",
    "    print up /(down + up)\n",
    "    \n",
    "up = 0\n",
    "down = 0\n",
    "\n",
    "for x in range(9, 12):\n",
    "    for row in test_all:\n",
    "\n",
    "        if float(row[x]) > 0:\n",
    "            up += 1\n",
    "        else:\n",
    "            down += 1\n",
    "\n",
    "\n",
    "    print up /(down + up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.04343546e-04,   5.53973169e-04,   2.42220999e-05],\n",
       "       [ -8.04210344e-05,   9.76484813e-05,  -2.57479382e-04],\n",
       "       [  1.47497233e-04,   4.35951735e-04,   2.55399675e-04],\n",
       "       ..., \n",
       "       [ -2.98248330e-04,  -5.89790747e-05,  -1.05683458e-04],\n",
       "       [  3.41976220e-04,   7.94172948e-04,   4.45385431e-04],\n",
       "       [ -3.92246878e-05,  -1.75840890e-05,  -3.13989063e-04]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = 'usd_eur_testingdata.csv'\n",
    "model_file = 'network.pkl'\n",
    "output_predictions_file = 'predictions.txt'\n",
    "\n",
    "# load model\n",
    "\n",
    "net = pickle.load( open( model_file, 'rb' ))\n",
    "ds = SupervisedDataSet(9, 3)\n",
    "for t in train:\n",
    "    ds.addSample(t[0], t[1])\n",
    "\n",
    "net.activateOnDataset( ds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
